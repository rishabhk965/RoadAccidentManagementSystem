{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18139ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape X (0, 300, 300, 1)\n",
      "\n",
      "Saving model weights and configuration file\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#_training_code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.callbacks import EarlyStopping, Callback\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Lambda, ELU,GlobalAveragePooling2D\n",
    "from keras import regularizers\n",
    "from keras.layers.convolutional import Convolution2D, Cropping2D, Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils import np_utils\n",
    "import time, cv2, glob\n",
    "global inputShape,size\n",
    "def kerasModel4():\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(16, (8, 8), strides=(4, 4), padding='valid', input_shape=(size,size,1)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(32, (5, 5), padding=\"same\"))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(GlobalAveragePooling2D())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Dropout(.1))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(2))\n",
    "        model.add(Activation('softmax'))\n",
    "        return model\n",
    "size=300\n",
    " ## load Training data : pothole\n",
    "potholeTrainImages = glob.glob(\"/home/lucky/Documents/Road-Accident-Management-System/Pot-Hole-Detction/pot-hole1.jpeg\")\n",
    "potholeTrainImages.extend(glob.glob(\"/home/lucky/Documents/Road-Accident-Management-System/Pot-Hole-Detction/pot-hole2.jpeg\"))\n",
    "potholeTrainImages.extend(glob.glob(\"/home/lucky/Documents/Road-Accident-Management-System/Pot-Hole-Detction/pot-hole1.jpeg\"))\n",
    "train1 = [cv2.imread(img,0) for img in potholeTrainImages]\n",
    "for i in range(0,len(train1)):\n",
    "    train1[i] = cv2.resize(train1[i],(size,size))\n",
    "temp1 = np.asarray(train1)\n",
    "#  ## load Training data : non-pothole\n",
    "nonPotholeTrainImages = glob.glob(\"/home/lucky/Documents/Road-Accident-Management-System/Pot-Hole-Detction/pot-hole3.jpeg\")\n",
    "train2 = [cv2.imread(img,0) for img in nonPotholeTrainImages]\n",
    "for i in range(0,len(train2)):\n",
    "    train2[i] = cv2.resize(train2[i],(size,size))\n",
    "temp2 = np.asarray(train2)\n",
    "## load Testing data : non-pothole\n",
    "nonPotholeTestImages = glob.glob(\"/home/lucky/Documents/Road-Accident-Management-System/Pot-Hole-Detction/pot-hole2.jpeg\")\n",
    "test2 = [cv2.imread(img,0) for img in nonPotholeTestImages]\n",
    "for i in range(0,len(test2)):\n",
    "    test2[i] = cv2.resize(test2[i],(size,size))\n",
    "temp4 = np.asarray(test2)\n",
    "potholeTestImages = glob.glob(\"/home/lucky/Documents/Road-Accident-Management-System/Pot-Hole-Detction/pot-hole1.jpeg\")\n",
    "test1 = [cv2.imread(img,0) for img in potholeTestImages]\n",
    "for i in range(0,len(test1)):\n",
    "    test1[i] = cv2.resize(test1[i],(size,size))\n",
    "temp3 = np.asarray(test1)\n",
    "X_train = []\n",
    "X_train.extend(temp1)\n",
    "X_train.extend(temp2)\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = []\n",
    "X_test.extend(temp3)\n",
    "X_test.extend(temp4)\n",
    "X_test = np.asarray(X_test)\n",
    "# print(train1)\n",
    "y_train1 = np.ones([temp1.shape[0]],dtype = int)\n",
    "y_train2 = np.zeros([temp2.shape[0]],dtype = int)\n",
    "y_test1 = np.ones([temp3.shape[0]],dtype = int)\n",
    "y_test2 = np.zeros([temp4.shape[0]],dtype = int)\n",
    "print(y_train1[0])\n",
    "print(y_train2[0])\n",
    "print(y_test1[0])\n",
    "print(y_test2[0])\n",
    "y_train = []\n",
    "y_train.extend(y_train1)\n",
    "y_train.extend(y_train2)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = []\n",
    "y_test.extend(y_test1)\n",
    "y_test.extend(y_test2)\n",
    "y_test = np.asarray(y_test)\n",
    "X_train,y_train = shuffle(X_train,y_train)\n",
    "X_test,y_test = shuffle(X_test,y_test)\n",
    "X_train = X_train.reshape(X_train.shape[0], size, size, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], size, size, 1)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "print(\"train shape X\", X_train.shape)\n",
    "print(\"train shape y\", y_train.shape)\n",
    "\n",
    "inputShape = (size, size, 1)\n",
    "model = kerasModel4()\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=1000,validation_split=0.1)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "metricsTrain = model.evaluate(X_train, y_train)\n",
    "print(\"Training Accuracy: \",metricsTrain[1]*100,\"%\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "metricsTest = model.evaluate(X_test,y_test)\n",
    "print(\"Testing Accuracy: \",metricsTest[1]*100,\"%\")\n",
    "\n",
    "print(\"Saving model weights and configuration file\")\n",
    "model.save('latest_full_model.h5')\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cc199e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
